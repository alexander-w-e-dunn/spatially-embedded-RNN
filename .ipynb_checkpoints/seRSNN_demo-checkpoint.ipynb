{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/8erberg/spatially-embedded-RNN/blob/main/seRSNN_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxkPNta0LWAH"
   },
   "source": [
    "# seRSNN: How to spatially-embed a recurrent spiking neural network\n",
    "\n",
    "In this notebook, we demonstrate how to spatially-embed a recurrent spiking neural network and train it on a classic neuromorphic classification task for spiking models. We hope to provide this framework, which applies biologically-inspired spatial and communicability constraints to RSNNs, for open-access use by researchers in the field.\n",
    "\n",
    "This notebook was created by Andrew Ham.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OqQ995MHxToh",
    "outputId": "b5f8c7e1-d891-4077-fdad-27477c6b0d23"
   },
   "outputs": [],
   "source": [
    "#Install packages -----\n",
    "\n",
    "'''\n",
    "snnTorch is a package that provides gradient-based learning for spiking neural networks and integrates various spiking neuron models with the PyTorch framework.\n",
    "Tonic is a package designed specifically for downloading, extracting, and manipulating various neuromorphic datasets.\n",
    "'''\n",
    "\n",
    "!pip install -q 'snntorch == 0.6.1'\n",
    "!pip install -q 'tonic == 1.2.5'\n",
    "!pip install -q bctpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "avb9VFDPMbeR"
   },
   "outputs": [],
   "source": [
    "#Import packages -----\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "import snntorch.functional as SF\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import tonic\n",
    "import tonic.transforms as transforms\n",
    "from tonic import DiskCachedDataset\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import bct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kshgL6DydVkH",
    "outputId": "a818b352-e001-4c6d-ec58-7ae8d3959f1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10a536c10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set random seeds -----\n",
    "\n",
    "np.random.seed(211)\n",
    "random.seed(211)\n",
    "torch.manual_seed(211)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1UMu8JtigS-"
   },
   "source": [
    "##Preparing the DVS Gesture dataset\n",
    "\n",
    "The following code downloads and extracts the DVS128 Gesture dataset provided by IBM (https://research.ibm.com/interactive/dvsgesture/). Manipulations of the dataset are possible as desired through Tonic and torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172,
     "referenced_widgets": [
      "ad7afcc9cb544824964cc6bbcfd11493",
      "6bd649d02f274ea4aed2d174c4ae0810",
      "c86291d2f5c849f7929e9ca71dfb4480",
      "28357b2866c64393b2cc79c043a0ac18",
      "83925c8f14a24976b14313a211904e18",
      "0ed2f9f8c6ab42b1850b1d21444fe4c0",
      "68b747625b0f4ea19ae20aac2652cb29",
      "cd77b695df1d4520ace79b4e9b9f5825",
      "f9eeff47680a4e76b0f043847b033798",
      "5cd9477554b44c9e9ad4e36ca556028e",
      "2ac472faaf7b4148a6aed429f15438a1",
      "005473cd985a470b92cdd6b8c44bef01",
      "5b84822f86b6498d9c9b26cd0d70f5ea",
      "fe743b3a916b4f70b2ad2258896fc2f5",
      "e9632231cff14bf2a3983028f406ac69",
      "88191f17f4b640528a8633009164128f",
      "eba66d23a22f443b8422ac0e35e81538",
      "efab384b04a74626a0e7bf1f9f578450",
      "61462ecced1c4864b0adbd00c390967f",
      "ea6b020fb3bf48a0916f679eae9e1512",
      "396da64cb69e41e2a6dcfdd06884cc1b",
      "fec838355f9c4afbb99688ea3bb1a6f1"
     ]
    },
    "id": "0NnuHfH2ddMl",
    "outputId": "16b8ddcf-46bc-42d1-8e47-b3d617456d39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/38022171/ibmGestureTrain.tar.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20231026/eu-west-1/s3/aws4_request&X-Amz-Date=20231026T021216Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=374b80183ecb44bc886e4826d8917a35d5f98563ef671b46ac74ba5e8d913a8c to ./data/DVSGesture/ibmGestureTrain.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b002ea62c047f39799a1dad66a3f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2443675558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Download and extract DVS Gesture dataset -----\n",
    "\n",
    "'''\n",
    "Downloading and extracting the dataset will take approximately 5 minutes.\n",
    "'''\n",
    "\n",
    "#Define variables (batch size, sensor size)\n",
    "batch_size = 64\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "sensor_size = tonic.datasets.DVSGesture.sensor_size\n",
    "\n",
    "#Define transformations\n",
    "frame_transform = transforms.Compose([transforms.ToFrame(sensor_size=sensor_size, n_time_bins = 20), transforms.DropEvent(p = 0.001)])\n",
    "\n",
    "#Define training and test sets\n",
    "DVS_train = tonic.datasets.DVSGesture(save_to='./data', transform=frame_transform, train=True)\n",
    "DVS_test = tonic.datasets.DVSGesture(save_to='./data', transform=frame_transform, train=False)\n",
    "\n",
    "#Create dataloaders\n",
    "trainloader = DataLoader(DVS_train, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle = True, drop_last = True)\n",
    "testloader = DataLoader(DVS_test, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TasTFNW9dl9t"
   },
   "source": [
    "## Initializing membrane time constants\n",
    "\n",
    "As in Perez-Nieves et al. ([2021](https://www.nature.com/articles/s41467-021-26022-3)), membrane time constants are heterogeneously initialized with a random gamma distribution and constrained within a biologically-realistic range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JydLp5fodevi"
   },
   "outputs": [],
   "source": [
    "#Initialize membrane time constant distribution -----\n",
    "\n",
    "'''\n",
    "This section defines two functions: a clipping function and an initialization function. Membrane parameters are taken from Perez-Nieves et al. in order to standardize network comparisons.\n",
    "'''\n",
    "\n",
    "#Membrane parameters\n",
    "tau_mem = 20e-3\n",
    "dist_shape = 3\n",
    "time_step = 0.5e-3\n",
    "\n",
    "#Clipping function\n",
    "def clip_tc(x):\n",
    "    clipped_tc = x.clamp_(0.7165, 0.995)\n",
    "    return clipped_tc\n",
    "\n",
    "#Initialize membrane time constant distribution\n",
    "def init_tc():\n",
    "    dist_gamma = np.random.gamma(dist_shape, tau_mem / 3, 100)\n",
    "    dist_beta = torch.from_numpy(np.exp(-time_step / dist_gamma))\n",
    "    clipped_beta = clip_tc(dist_beta)\n",
    "    return clipped_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsUB8P8teGRZ"
   },
   "source": [
    "##Model architecture\n",
    "\n",
    "We define the recurrent spiking neural network in this section. The snnTorch package is used to instantiate unit neurons as recurrent LIF models (for the hidden layer) and LIF models (for the readout layer). PyTorch is used to create the linear connections between layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l8vtSfsiebgf"
   },
   "outputs": [],
   "source": [
    "#Model architecture -----\n",
    "\n",
    "'''\n",
    "self.lif1, which defines the recurrent layer, uses snn.RLeaky to instantiate recurrent LIF neurons, and the parameter learn_beta is set to True to allow time constants to be learnable and updated alongside weights and biases. \n",
    "'''\n",
    "\n",
    "#Size parameters\n",
    "num_inputs = 128*128*2\n",
    "num_hidden = 100\n",
    "num_outputs = 11\n",
    "\n",
    "#Network parameters\n",
    "het_tau = init_tc().to(device)\n",
    "hom_tau = 0.9753\n",
    "\n",
    "#Optimization mechanism\n",
    "spike_grad = surrogate.fast_sigmoid(slope = 100)\n",
    "\n",
    "#Model definition\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.RLeaky(beta = het_tau, linear_features = num_hidden, learn_beta = True, spike_grad = spike_grad)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta = hom_tau, spike_grad = spike_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #Initialize parameters\n",
    "        spk1, mem1 = self.lif1.init_rleaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        #Record output layer\n",
    "        spk_out_rec = []\n",
    "        mem_out_rec = []\n",
    "        \n",
    "        #Forward loop\n",
    "        for step in range(data.size(0)):\n",
    "            batched_data = data[step].view(batch_size, num_inputs)\n",
    "            cur1 = self.fc1(batched_data)\n",
    "            spk1, mem1 = self.lif1(cur1, spk1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "\n",
    "            spk_out_rec.append(spk2)\n",
    "            mem_out_rec.append(mem2)\n",
    "\n",
    "        #Convert output lists to tensors\n",
    "        spk_out_rec = torch.stack(spk_out_rec)\n",
    "        mem_out_rec = torch.stack(mem_out_rec)\n",
    "        \n",
    "        return spk_out_rec, mem_out_rec\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhxX1g3eet7o"
   },
   "outputs": [],
   "source": [
    "#Extract membrane time constants (pre-training) -----\n",
    "\n",
    "'''\n",
    "The random initialization of time constants is saved pre-training in order to make comparisons to time constant distributions after each epoch of training.\n",
    "'''\n",
    "\n",
    "tc_hist = []\n",
    "pretrain_tau = (-time_step / np.log(het_tau.cpu())) / 1e-3\n",
    "tc_hist.append(pretrain_tau.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWBWddIzewcf"
   },
   "outputs": [],
   "source": [
    "#Optimizer and loss function -----\n",
    "\n",
    "'''\n",
    "This demonstration uses the Adam optimizer with basic hyperparameters.\n",
    "The loss is the mean square error spike count loss, a snnTorch function that calculates the total spike count of each neuron and calculates the MSE loss against target spike counts. \n",
    "'''\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 1e-3, betas = (0.9, 0.999))\n",
    "loss_fn = SF.mse_count_loss(correct_rate = 0.8, incorrect_rate = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rh8fQ9vhkt4r"
   },
   "source": [
    "##Creating the Euclidean matrix\n",
    "\n",
    "This section creates the Euclidean distance matrix for spatial embedding. Weights between hidden layer units are weighted by the distance between them in this defined 3D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BomRz5W6eypG"
   },
   "outputs": [],
   "source": [
    "#Distance matrix -----\n",
    "network_structure = [5, 5, 4]\n",
    "distance_metric = 'euclidean'\n",
    "distance_power = 1\n",
    "\n",
    "#Define each dimension's neurons\n",
    "nx = np.arange(network_structure[0])\n",
    "ny = np.arange(network_structure[1])\n",
    "nz = np.arange(network_structure[2])\n",
    "\n",
    "#Create coordinate grid\n",
    "[x,y,z] = np.meshgrid(nx,ny,nz)\n",
    "coordinates = [x.ravel(),y.ravel(),z.ravel()]\n",
    "\n",
    "#Calculate Euclidean distance matrix\n",
    "euclidean_vector = scipy.spatial.distance.pdist(np.transpose(coordinates), metric=distance_metric)\n",
    "euclidean = scipy.spatial.distance.squareform(euclidean_vector**distance_power)\n",
    "distance_matrix = euclidean.astype('float64')\n",
    "\n",
    "#Create tensor from distance matrix\n",
    "distance_matrix = torch.from_numpy(distance_matrix).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xB8RVRDOe4FY"
   },
   "source": [
    "##Validation of spatial embedding\n",
    "\n",
    "In this section we define a function that will correlate the recurrent weight and distance matrices to validate our method of spatial embedding. If successful, spatial embedding should produce a negative correlation between the two matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HeHjkUjje3dz",
    "outputId": "1dc08c2f-ad92-4a19-f489-7c5a21360d29"
   },
   "outputs": [],
   "source": [
    "#Diagnostic tests -----\n",
    "\n",
    "#Test for spatial regularization\n",
    "def test_euclidean(x, y):\n",
    "    x = torch.abs(x)\n",
    "    x_array = x.detach().cpu().numpy()\n",
    "    flat_x_array = x_array.flatten()\n",
    "    y = torch.abs(y)\n",
    "    y_array = y.detach().cpu().numpy()\n",
    "    flat_y_array = y_array.flatten()\n",
    "    correlation = pearsonr(flat_x_array, flat_y_array)[0]\n",
    "    return correlation\n",
    "\n",
    "print(f\"Initial, pre-training correlation between distance and weight matrices (should be approx. 0): {test_euclidean(distance_matrix, net.lif1.recurrent.weight)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IXlpD-MfLbz"
   },
   "source": [
    "##Model training\n",
    "\n",
    "In each training loop, communicability and spatial regularization are applied to the absolute recurrent weight matrix and returned as part of the loss. This regularization is weighted by the term regu_strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tSFUHu9SxOUC",
    "outputId": "2daa30f9-8279-4e43-c110-09e4a6d336a5"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Spatial and communicability regularization is applied to standard L1 regularization in the training process.\n",
    "The communicability term used here is unbiased weighted communicability:\n",
    "Crofts, J. J., & Higham, D. J. (2009). A weighted communicability measure applied to complex brain networks. Journal of the Royal Society Interface, 6(33), 411-414.\n",
    "'''\n",
    "\n",
    "#Training parameters\n",
    "num_epochs = 50\n",
    "comms_factor = 1\n",
    "\n",
    "#Regularization parameters\n",
    "regu_strength = 1e-05\n",
    "\n",
    "#Initialize variables of interest\n",
    "train_loss_hist = []\n",
    "train_acc_hist = []\n",
    "rec_tot_hist = []\n",
    "corr_hist = []\n",
    "test_acc_hist = []\n",
    "test_loss_hist = []\n",
    "weight_matrix = []\n",
    "\n",
    "#Pre-training extractions -- calculate correlation (distance, weights) and total weights before training\n",
    "rec_tot_hist.append(torch.sum(torch.abs(net.lif1.recurrent.weight.detach())))\n",
    "corr_hist.append(test_euclidean(distance_matrix, net.lif1.recurrent.weight))\n",
    "\n",
    "#Training loop\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for i, (data, targets) in enumerate(iter(trainloader)):\n",
    "\n",
    "        #Load data on CUDA\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        #Set model to training mode\n",
    "        net.train()\n",
    "        spk_outputs, mem_outputs = net(data)\n",
    "\n",
    "        #Create absolute weight matrix\n",
    "        abs_weight_matrix = torch.abs(net.lif1.recurrent.weight.detach()).to(device)\n",
    "\n",
    "        #Calculate communicability\n",
    "        step1 = torch.sum(abs_weight_matrix, dim = 1) #Sum matrix along columns (keep rows, elim. cols)\n",
    "        step2 = torch.pow(step1, -0.5) #Take exponent of matrix\n",
    "        step3 = torch.diag(step2) #Return 2D tensor with elements of step2 vector as the diagonal\n",
    "        step4 = torch.linalg.matrix_exp(step3@abs_weight_matrix@step3) #Matrix multiplication of step3 and abs, then exponentiate\n",
    "        comms_matrix = step4.fill_diagonal_(0) #Fill diagonal with 0s for gradient calculations\n",
    "        comms_matrix = comms_matrix ** comms_factor\n",
    "\n",
    "        comms_weight_matrix = torch.mul(comms_matrix, abs_weight_matrix) #Element-wise mult. of weights w/ communicability\n",
    "        \n",
    "        #Calculate spatial communicability loss\n",
    "        se_loss = regu_strength * torch.sum(torch.mul(comms_weight_matrix, distance_matrix)) #Mult. comms with distances\n",
    "\n",
    "        #Calculate loss\n",
    "        loss_val = loss_fn(spk_outputs, targets) + se_loss\n",
    "\n",
    "        #Gradient calculation and weight updates\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "        clip_tc(net.lif1.beta.detach())\n",
    "\n",
    "        #Store loss history\n",
    "        train_loss_hist.append(loss_val.item())\n",
    "\n",
    "    #Evaluations (every epoch)\n",
    "    net.eval()\n",
    "\n",
    "    #Training accuracy\n",
    "    acc = SF.accuracy_rate(spk_outputs, targets)\n",
    "    train_acc_hist.append(acc)\n",
    "\n",
    "    #Sum of regularized weights\n",
    "    rec_tot = torch.sum(torch.abs(net.lif1.recurrent.weight.detach()))\n",
    "    rec_tot_hist.append(rec_tot)\n",
    "\n",
    "    #Correlation of distance and weight matrices\n",
    "    corr_matrix = test_euclidean(distance_matrix, net.lif1.recurrent.weight.detach())\n",
    "    corr_hist.append(corr_matrix)\n",
    "\n",
    "    #Save membrane time constant matrix\n",
    "    converted_tc = (-time_step / np.log(net.lif1.beta.cpu().detach())) / 1e-3\n",
    "    tc_hist.append(converted_tc.numpy())\n",
    "\n",
    "    #Save weight matrix\n",
    "    weight_matrix.append(net.lif1.recurrent.weight.detach().cpu())\n",
    "\n",
    "    #Validation accuracy\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        for data, targets in testloader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            test_spk, test_mem = net(data)\n",
    "\n",
    "            _, predicted = test_spk.sum(dim=0).max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            test_loss = loss_fn(test_spk, targets) + se_loss\n",
    "\n",
    "        test_acc_hist.append(correct / total)\n",
    "        test_loss_hist.append(test_loss.item())\n",
    "\n",
    "    #Print statements\n",
    "    if epoch % 5 == 0:\n",
    "      print(f\"Epoch {epoch}/{num_epochs} === Train loss: {loss_val.item():.2f} --- \", end = \"\")\n",
    "      print(f\"Train accuracy: {acc * 100:.2f}% --- \", end = \"\")\n",
    "      print(f\"Val. loss: {test_loss.item():.2f} --- \", end = \"\")\n",
    "      print(f\"Val. accuracy: {100 * correct / total:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHP_wq8KlMin"
   },
   "source": [
    "##Data visualizations\n",
    "\n",
    "In this section we create basic plots summarizing the trained model's training and validation performance, total weight, and the correlation between weights and unit distances over the 50 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "hhV8Q3kQlMGd",
    "outputId": "52612bae-a60f-4d5a-d035-f581d14154bd"
   },
   "outputs": [],
   "source": [
    "#Training accuracy\n",
    "plt.figure(figsize=(3.3,2),dpi=150)\n",
    "train_acc_hist.insert(0, 0)\n",
    "plt.plot(train_acc_hist, color = '#ff1f5b')\n",
    "plt.xlabel('Epoch', fontsize = 8)\n",
    "plt.ylabel('Training accuracy', fontsize = 8)\n",
    "plt.tick_params(axis='both', labelsize=6)\n",
    "plt.title('Accuracy over training epochs', fontsize = 9, pad = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "9BeVuX8CN0vR",
    "outputId": "c8c3c153-7e42-4b14-fe0c-2f3f3ee79631"
   },
   "outputs": [],
   "source": [
    "#Validation accuracy\n",
    "plt.figure(figsize=(3.3,2),dpi=150)\n",
    "test_acc_hist.insert(0,0)\n",
    "plt.plot(test_acc_hist, color = '#ff1f5b')\n",
    "plt.xlabel('Epoch', fontsize = 8)\n",
    "plt.ylabel('Validation accuracy', fontsize = 8)\n",
    "plt.tick_params(axis='both', labelsize=6)\n",
    "plt.title('Validation accuracy over training epochs', fontsize = 9, pad = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "7IdVD7c8xvSI",
    "outputId": "9b2f1d6a-749a-48f4-a638-eeb335d5e275"
   },
   "outputs": [],
   "source": [
    "#Total recurrent weight\n",
    "\n",
    "'''\n",
    "The sum of regularized weights decreases over training epochs, demonstrating the effect of spatial and communicability regularization.\n",
    "'''\n",
    "\n",
    "rec_tot_hist = torch.FloatTensor(rec_tot_hist)\n",
    "plt.figure(figsize=(3.3,2),dpi=150)\n",
    "plt.plot(rec_tot_hist.cpu(), color = '#ff1f5b')\n",
    "plt.xlabel('Epoch', fontsize = 8)\n",
    "plt.ylabel('Total regularized weight', fontsize = 8)\n",
    "plt.tick_params(axis='both', labelsize=6)\n",
    "plt.title('Total weight over training epochs', fontsize = 9, pad = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "aP2BxraPxwdi",
    "outputId": "240f28a1-3c88-42e1-f0c9-3788f693db6a"
   },
   "outputs": [],
   "source": [
    "#Correlation of distance/weight matrices\n",
    "\n",
    "'''\n",
    "The correlation between weights and distances decreases (indicating that longer distances will be incentivized to decrease their weights, and vice versa) over training, initially decreasing rapidly and recovering to approximately -0.3.\n",
    "'''\n",
    "\n",
    "plt.figure(figsize=(3.3,2),dpi=150)\n",
    "corr_hist = torch.FloatTensor(corr_hist)\n",
    "plt.plot(corr_hist.cpu(), color = '#ff1f5b')\n",
    "plt.xlabel('Epoch', fontsize = 8)\n",
    "plt.ylabel('Correlation (distance, weight)', fontsize = 8)\n",
    "plt.tick_params(axis='both', labelsize=6)\n",
    "plt.title('Correlation (distance, weight)', fontsize = 9, pad = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3FrFibAmXmr"
   },
   "source": [
    "##Structural analyses\n",
    "In this section, we demonstrate how to conduct analyses of the model structure/topology over the course of training. We focus on two particular measures of network topology, modularity and small-worldness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxegQPlrnbnT"
   },
   "source": [
    "###Modularity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "hVPpL4JBnd4x",
    "outputId": "124ec22a-03b4-4221-9c12-d8fc73cce744"
   },
   "outputs": [],
   "source": [
    "#Calculate modularity of model after each epoch\n",
    "\n",
    "'''\n",
    "Network modularity increases monotonically over training, reaching a final value of 0.46.\n",
    "'''\n",
    "\n",
    "mods = []\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "\n",
    "for epoch in range(0, num_epochs):\n",
    "  extracted_weights = weight_matrix[epoch]\n",
    "  abs_matrix = np.abs(extracted_weights)\n",
    "  weights = abs_matrix.numpy()\n",
    "  _, q_stat = bct.modularity_und(weights, gamma = 1)\n",
    "  mods.append(q_stat)\n",
    "\n",
    "print(f'Final modularity of the network: {mods[49]}\\n')\n",
    "\n",
    "#Plot modularity\n",
    "plt.figure(figsize=(3.3,2),dpi=150)\n",
    "plt.plot(mods, color = '#ff1f5b')\n",
    "plt.xlabel('Epochs', fontsize = 8)\n",
    "plt.ylabel('Modularity', fontsize = 8)\n",
    "plt.tick_params(axis='both', labelsize=6)\n",
    "plt.title('Network modularity over training', fontsize = 9, pad = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBGsjolDpGPi"
   },
   "source": [
    "###Small-worldness calculation and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "x5EFPLhXpDak",
    "outputId": "416a629f-a703-4832-d894-819b3d3127f3"
   },
   "outputs": [],
   "source": [
    "#Calculate small-worldness of model after each epoch\n",
    "\n",
    "'''\n",
    "Network small-worldness also increases over training epochs, and reaches a final value of 4.2. The technical definition of a \"small-world\" network is one with a small-worldness value of > 1.\n",
    "'''\n",
    "\n",
    "sw = []\n",
    "\n",
    "for epoch in range(0, num_epochs):\n",
    "  extracted_weights = weight_matrix[epoch]\n",
    "  abs_matrix = np.abs(extracted_weights)\n",
    "  binary_weight_matrix = abs_matrix.numpy().copy()\n",
    "  thresh = np.quantile(abs_matrix, q=0.9)\n",
    "  matrix_mask = abs_matrix > thresh\n",
    "  binary_weight_matrix[matrix_mask] = 1\n",
    "  binary_weight_matrix[~matrix_mask] = 0\n",
    "\n",
    "  A = binary_weight_matrix\n",
    "  clu = np.mean(bct.clustering_coef_bu(A))\n",
    "  pth = bct.efficiency_bin(A)\n",
    "\n",
    "  #Run nperm null models\n",
    "\n",
    "  nperm = 1000\n",
    "  cluperm = np.zeros((nperm,1))\n",
    "  pthperm = np.zeros((nperm,1))\n",
    "\n",
    "  for perm in range(nperm):\n",
    "    Wperm = np.random.rand(100,100)\n",
    "\n",
    "    #Make it into a matrix\n",
    "    Wperm = np.matrix(Wperm)\n",
    "\n",
    "    #Make symmetrical\n",
    "    Wperm = Wperm+Wperm.T\n",
    "    Wperm = np.divide(Wperm,2)\n",
    "\n",
    "    #Binarise\n",
    "    threshold, upper, lower = .7,1,0\n",
    "    Aperm = np.where(Wperm>threshold,upper,lower)\n",
    "\n",
    "    #Take null model\n",
    "    cluperm[perm] = np.mean(bct.clustering_coef_bu(Aperm))\n",
    "    pthperm[perm] = bct.efficiency_bin(Aperm)\n",
    "\n",
    "  #Take the average of the nulls\n",
    "  clunull = np.mean(cluperm)\n",
    "  pthnull = np.mean(pthperm)\n",
    "\n",
    "  #Compute the small worldness\n",
    "  smw = np.divide(np.divide(clu,clunull),np.divide(pth,pthnull))\n",
    "  sw.append(smw)\n",
    "\n",
    "print(f'Final small-worldness of the network: {sw[49]}\\n')\n",
    "\n",
    "#Plot small-worldness\n",
    "plt.figure(figsize=(3.3,2),dpi=150)\n",
    "plt.plot(sw, color = '#ff1f5b')\n",
    "plt.xlabel('Epochs', fontsize = 8)\n",
    "plt.ylabel('Small-worldness', fontsize = 8)\n",
    "plt.tick_params(axis='both', labelsize=6)\n",
    "plt.title('Network small-worldness over training', fontsize = 9, pad = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "005473cd985a470b92cdd6b8c44bef01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b84822f86b6498d9c9b26cd0d70f5ea",
       "IPY_MODEL_fe743b3a916b4f70b2ad2258896fc2f5",
       "IPY_MODEL_e9632231cff14bf2a3983028f406ac69"
      ],
      "layout": "IPY_MODEL_88191f17f4b640528a8633009164128f"
     }
    },
    "0ed2f9f8c6ab42b1850b1d21444fe4c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28357b2866c64393b2cc79c043a0ac18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5cd9477554b44c9e9ad4e36ca556028e",
      "placeholder": "​",
      "style": "IPY_MODEL_2ac472faaf7b4148a6aed429f15438a1",
      "value": " 2443675648/? [01:13&lt;00:00, 34587161.31it/s]"
     }
    },
    "2ac472faaf7b4148a6aed429f15438a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "396da64cb69e41e2a6dcfdd06884cc1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b84822f86b6498d9c9b26cd0d70f5ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eba66d23a22f443b8422ac0e35e81538",
      "placeholder": "​",
      "style": "IPY_MODEL_efab384b04a74626a0e7bf1f9f578450",
      "value": ""
     }
    },
    "5cd9477554b44c9e9ad4e36ca556028e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61462ecced1c4864b0adbd00c390967f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68b747625b0f4ea19ae20aac2652cb29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6bd649d02f274ea4aed2d174c4ae0810": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ed2f9f8c6ab42b1850b1d21444fe4c0",
      "placeholder": "​",
      "style": "IPY_MODEL_68b747625b0f4ea19ae20aac2652cb29",
      "value": ""
     }
    },
    "83925c8f14a24976b14313a211904e18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88191f17f4b640528a8633009164128f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad7afcc9cb544824964cc6bbcfd11493": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6bd649d02f274ea4aed2d174c4ae0810",
       "IPY_MODEL_c86291d2f5c849f7929e9ca71dfb4480",
       "IPY_MODEL_28357b2866c64393b2cc79c043a0ac18"
      ],
      "layout": "IPY_MODEL_83925c8f14a24976b14313a211904e18"
     }
    },
    "c86291d2f5c849f7929e9ca71dfb4480": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd77b695df1d4520ace79b4e9b9f5825",
      "max": 2443675558,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9eeff47680a4e76b0f043847b033798",
      "value": 2443675558
     }
    },
    "cd77b695df1d4520ace79b4e9b9f5825": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9632231cff14bf2a3983028f406ac69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_396da64cb69e41e2a6dcfdd06884cc1b",
      "placeholder": "​",
      "style": "IPY_MODEL_fec838355f9c4afbb99688ea3bb1a6f1",
      "value": " 691456000/? [00:21&lt;00:00, 33858265.26it/s]"
     }
    },
    "ea6b020fb3bf48a0916f679eae9e1512": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eba66d23a22f443b8422ac0e35e81538": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efab384b04a74626a0e7bf1f9f578450": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9eeff47680a4e76b0f043847b033798": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe743b3a916b4f70b2ad2258896fc2f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61462ecced1c4864b0adbd00c390967f",
      "max": 691455012,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ea6b020fb3bf48a0916f679eae9e1512",
      "value": 691455012
     }
    },
    "fec838355f9c4afbb99688ea3bb1a6f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
